# ğŸ§® Sales Analytics Project using SQL and Python

This project demonstrates how to perform **data analysis** on the [Online Retail II Dataset](https://www.kaggle.com/datasets/mashlyn/online-retail-ii-uci) using **MySQL and Python**. It walks through the full data pipeline: importing data, setting up SQL schema, connecting SQL to Python, performing exploratory data analysis (EDA), and customer segmentation.

---

## ğŸ“ Project Structure

```
Sales_Analytics/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ online_retail_II.csv           # Raw dataset
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ sql_schema.sql                 # SQL schema and insert queries
â”‚   â””â”€â”€ eda_analysis.py                # Python code for EDA and clustering
â”œâ”€â”€ README.md                          # Project documentation
â””â”€â”€ customer_segments.csv              # Output from clustering analysis
```

---

## âš™ï¸ Prerequisites

- Python 3.x
- MySQL Server
- MySQL Workbench or CLI
- Python Libraries:
  - `pandas`
  - `sqlalchemy`
  - `pymysql`
  - `matplotlib`
  - `seaborn`
  - `scikit-learn`

Install them using:

```bash
pip install pandas sqlalchemy pymysql matplotlib seaborn scikit-learn
```

---

## ğŸ§µ Step-by-Step Guide

### 1ï¸âƒ£ Load Dataset into Python

```python
import pandas as pd

df = pd.read_csv("online_retail_II.csv")
df.dropna(subset=["Customer ID"], inplace=True)
df['Customer ID'] = df['Customer ID'].astype(int)
df['Total'] = df['Quantity'] * df['Price']
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
```

---

### 2ï¸âƒ£ Create SQL Tables in MySQL

Run the following in MySQL Workbench:

```sql
CREATE DATABASE Sales_Analytics;
USE Sales_Analytics;

CREATE TABLE RawRetail (
    Invoice VARCHAR(20),
    StockCode VARCHAR(20),
    Description TEXT,
    Quantity INT,
    InvoiceDate DATETIME,
    Price DECIMAL(10, 2),
    CustomerID INT,
    Country VARCHAR(100)
);
```

---

### 3ï¸âƒ£ Connect Python to MySQL

#### ğŸ” Format:

```python
from sqlalchemy import create_engine

engine = create_engine("mysql+pymysql://username:password@localhost:3306/Sales_Analytics")
```

Example:

```python
engine = create_engine("mysql+pymysql://root:Durga76@localhost:3306/Sales_Analytics")
```

> âš ï¸ Replace `root`, `Durga76`, `localhost`, and `Sales_Analytics` with your actual MySQL username, password, host, and database name.

---

### 4ï¸âƒ£ Upload DataFrame to SQL

```python
df.to_sql('RawRetail', con=engine, if_exists='replace', index=False)
```

---

### 5ï¸âƒ£ Analyze the Data from SQL in Python

```python
query = """
    SELECT InvoiceDate, StockCode, Description, Quantity, Price, CustomerID, Country, 
           (Quantity * Price) AS Total 
    FROM RawRetail;
"""
df = pd.read_sql(query, con=engine)

# Monthly Sales Trend
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
monthly_sales = df.groupby(df['InvoiceDate'].dt.to_period('M'))['Total'].sum()
monthly_sales.plot(kind='line', title='Monthly Sales Trend')
```

---

### 6ï¸âƒ£ RFM Segmentation (Customer Clustering)

```python
rfm = df.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (df['InvoiceDate'].max() - x.max()).days,
    'Invoice': 'nunique',
    'Total': 'sum'
})
rfm.columns = ['Recency', 'Frequency', 'Monetary']

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import seaborn as sns

scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm)

kmeans = KMeans(n_clusters=3, random_state=42)
rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)

sns.scatterplot(x='Recency', y='Monetary', hue='Cluster', data=rfm)
```

---

## ğŸ“Š Key Outputs

- Monthly sales trends
- Top-selling products
- Country-wise sales breakdown
- Customer clusters based on RFM segmentation

---

## ğŸ’¡ Highlights

- ğŸ”— SQL-to-Python pipeline using SQLAlchemy
- ğŸ“¦ Clean, scalable project structure
- ğŸ“ˆ Visual analytics using Matplotlib & Seaborn
- ğŸ” Insightful segmentation using machine learning

---

## ğŸ¤ Credits

- Dataset: [Kaggle - Online Retail II](https://www.kaggle.com/datasets/mashlyn/online-retail-ii-uci)
- Author: Durga Rani

---

## ğŸ› ï¸ Future Improvements

- Add interactive dashboard using Streamlit or Dash
- Schedule regular database updates
- Deploy model predictions for marketing use

---

## ğŸ“Œ License

This project is under the MIT License.
